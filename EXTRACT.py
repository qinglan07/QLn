import glob
import warnings
from pathlib import Path

import pandas as pd
from tqdm import tqdm
import opensmile
from sklearn.preprocessing import StandardScaler

warnings.filterwarnings("ignore", category=FutureWarning)

# ---------------------- 1. åŸºç¡€è·¯å¾„ ----------------------
BASE_DIR = Path("/home/oem/qinglan7/ICA/DATA/tt/")
SUBSETS = ["A", "E", "I", "O", "U", "KA", "PA", "TA"]

DATA_ORDER_CSV = Path("/home/oem/qinglan7/ICA/DATA/tt/DATA.CSV/DATA.csv")  # ID é¡ºåºæ–‡ä»¶
OUT_DIR = Path("/home/oem/qinglan7/ICA/DATA/tt/")
OUT_DIR.mkdir(parents=True, exist_ok=True)

# ---------------------- 2. è¯»å– DATA.csvï¼ˆç”¨äºæ’åºï¼‰ ----------------------
print("ğŸ›ˆ è¯»å– ID é¡ºåºæ–‡ä»¶ (DATA.csv) â€¦")
data_df = pd.read_csv(DATA_ORDER_CSV)
if "ID" not in data_df.columns:
    raise ValueError("âŒ DATA.csv ä¸­å¿…é¡»åŒ…å« 'ID' åˆ—")

# å»æ‰å‰ç¼€ "ID"ï¼Œç»Ÿä¸€ä¸ºæ•´æ•°å½¢å¼å­—ç¬¦ä¸²
DATA_ORDER_INT = [str(int(i.replace("ID", ""))) for i in data_df["ID"].tolist()]
print(f"DATA.csv ä¸­å…± {len(DATA_ORDER_INT)} æ¡ IDï¼ˆå°†ç”¨äºæ’åºï¼‰")

# ---------------------- 3. åˆå§‹åŒ– opensmile ----------------------
smile = opensmile.Smile(
    feature_set=opensmile.FeatureSet.ComParE_2016,
    feature_level=opensmile.FeatureLevel.Functionals,
)

# ============================================================
#           â­ ä¸»å¾ªç¯ï¼šé€ä¸ªå­æ–‡ä»¶å¤¹ï¼Œæå–ç‰¹å¾ + æ’åº â­
# ============================================================
for subset in SUBSETS:
    print(f"\n============================")
    print(f"â–¶â–¶ å¤„ç†å­æ–‡ä»¶å¤¹: {subset}")
    print(f"============================")

    AUDIO_DIR = BASE_DIR / subset
    wav_files = sorted(glob.glob(str(AUDIO_DIR / "*.wav")),
                       key=lambda x: int(Path(x).stem.replace("ID", "").split("_")[0]))

    print(f"åœ¨ {subset} ä¸­æ‰¾åˆ° {len(wav_files)} ä¸ªéŸ³é¢‘")

    features_list = []
    ids_list = []

    # ----------- æå–ç‰¹å¾ -----------
    for wav_path in tqdm(wav_files, desc=f"{subset} æå–ä¸­"):
        fname = Path(wav_path).stem   # e.g., ID004_xxx
        try:
            file_id = str(int(fname.replace("ID", "").split("_")[0]))
        except:
            print(f"âš  æ— æ³•è§£æID: {fname}")
            continue

        try:
            features = smile.process_file(wav_path).values.flatten()
        except Exception as e:
            print(f"âŒ ç‰¹å¾æå–å¤±è´¥: {wav_path} â†’ {e}")
            continue

        features_list.append(features)
        ids_list.append(file_id)

    # ----------- æ„å»º DataFrame -----------
    if len(features_list) == 0:
        print(f"âŒ {subset} æ²¡æœ‰æˆåŠŸæå–åˆ°ä»»ä½•ç‰¹å¾ï¼Œè·³è¿‡")
        continue

    X = pd.DataFrame(features_list, index=ids_list, columns=smile.feature_names)

    # ----------- æŒ‰ DATA.csv çš„ ID é¡ºåºæ’åº -----------
    X_sorted = X.reindex(DATA_ORDER_INT).dropna()
    print(f"ğŸ“Œ æ’åºåå‰©ä½™ {X_sorted.shape[0]} æ¡ï¼ˆé¡ºåºå®Œå…¨ä¸ DATA.csv ä¸€è‡´ï¼‰")

    # ----------- ä¿å­˜åŸå§‹ç‰¹å¾ -----------
    raw_df = pd.concat([
        pd.Series(X_sorted.index, name="ID"),
        X_sorted.reset_index(drop=True)
    ], axis=1)

    raw_path = OUT_DIR / f"{subset}_ComParE_raw.csv"
    raw_df.to_csv(raw_path, index=False)
    print(f"ğŸ“Œ åŸå§‹ç‰¹å¾ä¿å­˜è‡³ {raw_path}")

    # ----------- æ ‡å‡†åŒ– -----------
    scaler = StandardScaler()
    X_std = pd.DataFrame(scaler.fit_transform(X_sorted), columns=X_sorted.columns, index=X_sorted.index)

    std_df = pd.concat([
        pd.Series(X_std.index, name="ID"),
        X_std.reset_index(drop=True)
    ], axis=1)

    std_path = OUT_DIR / f"{subset}_ComParE_std.csv"
    std_df.to_csv(std_path, index=False)
    print(f"ğŸ“Œ æ ‡å‡†åŒ–ç‰¹å¾ä¿å­˜è‡³ {std_path}")

print("\nğŸ‰ å…¨éƒ¨åˆ†ç»„ç‰¹å¾æå–å®Œæˆï¼ˆé¡ºåºå·²å®Œå…¨å¯¹é½ DATA.csvï¼‰ï¼")
